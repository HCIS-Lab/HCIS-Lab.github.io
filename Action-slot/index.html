<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Action-Slot: Visual Action-centric Representation for Traffic Pattern Recognition"> 
  <meta name="keywords" content="Slot Attention, Traffic Pattern, Action Recognition">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Action-Slot: Visual Action-centric Representation for Traffic Pattern Recognition</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Action-Slot: Visual Action-centric Representation for Traffic Pattern Recognition</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block-name">
              <a href="https://hankkung.github.io/website/">Chi-Hsi Kung</a><sup>1</sup>,</span>
            <span class="author-block-name">
              <a href="">Shu-Wei Lu</a><sup>1</sup>,</span>
            <span class="author-block-name">
              <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai</a><sup>2</sup>,</span>
            <span class="author-block-name">
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National Yang Ming Chiao Tung University</span>
            <span class="author-block"><sup>2</sup>Google</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <!-- <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <div class="container is-max-desktop">
        <div class="content has-text-justified">
          <div class="flex-container">
            <img src="./static/videos/action_slot_viz.gif">
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section is-max-desktop">
  <div class="container is-max-desktop">
    <div class="column is-centered has-text-centered">
      <img src="./static/videos/action_slot_viz.gif">
    </div>
  </div>
</section>


<section class="section" id="abstract">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Recognizing traffic patterns is a crucial aspect for intelligent driving systems. To address the need for fine-grained traffic scene understanding, we introduce a dataset that is specifically designed for topology-aware traffic pattern recognition, framed as a multi-label action recognition task. We first identify the unique challenges of this task and explore the limitation of existing video action recognition methods. Then, we propose Action-Slot, a slot-attention-based approach that enables the learning of compact action-centric representations to capture both motion and contextual information. Our key idea is to design action slots that are capable of paying attention to regions where individual traffic patterns occur, without the need to explicitly provide perception guidance. To further enhance slot attention, we propose to use a background slot that competes with action slots, thus facilitating the training process not to focus on background regions where there are no activities. To validate the effectiveness of our method, we conduct comprehensive experiments and ablation studies against various action recognition baselines on the proposed dataset. We will make our dataset, code, and models available to the public.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section is-max-desktop">
  <div class="container is-max-desktop">
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3">Traffic Pattern Recognition</h2>
    </div>
    <div class="content has-text-justified">
      <img src="./static/images/teaser.png">
    </div>
    <div class="content has-text-justified">
      <p>
        Illustration of the topology-aware traffic pattern recognition task. Distinct categories of traffic patterns, represented by colored arrows, are defined based on semantic regions (such as roadways and corners) and object types. The objective is to predict the traffic patterns occurring in a scene from an egocentric video.
      </p>
    </div>
  </div>
</section>



<hr>

<section class="section is-max-desktop">
  <div class="container is-max-desktop">
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3">Action-slot Architecture</h2>
    </div>
<!--     <div class="content has-text-justified">
      <h3 style="text-align: center;">The Shape-Conditioned Trajectory Deformation Network (SCTDN)</h3>
    </div> -->
    <div class="content has-text-justified">
      <img src="./static/images/architecture.png">
    </div>
    <div class="content has-text-justified">
      <p>
        The top of the figure illustrates the proposed framework. Action-Slot first takes video as input and uses a 3D-CNN encoder to extract spatial-temporal feature patches. All patches are then processed with individual slots simultaneously to find the most relevant spatial-temporal patches corresponding to each action slot. After updating the action slots, all action slots are fed into a fully-connected layer to predict the probability of the corresponding action category, except for the background slot. The bottom of the figure depicts the attention maps of action and background slots. In addition, we propose to incorporate a background mask Mbg to supervise the background slot and facilitate the other slots to capture action signals. Moreover, we regularize slots allocated to negative classes (e.g., R3-R4: V) with an all-zero mask \(Mneg\).
      </p>
    </div>
  </div>
</section>

<hr>


<section class="section is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-five-fifths">
            <h2 class="title is-3">Dataset and Annotation Samples</h2>
            <div class="content has-text-justified">
              <!-- <p>
                description
              </p> -->
            </div>
          </div>
        </div>
      
        <div class="columns is-centered has-text-centered">
          <div class="column is-five-fifths">
            <h2 class="title is-4">TACO Dataset</h2>
            <div class="content has-text-centered">
              <!-- <video id="replay-video"
                      controls
                      muted
                      preload
                      playsinline
                      width="75%">
                <source src="./static/gif/localization_anticipation.gif"
                        type="video/webm">
              </video> -->
              <!-- Slideshow container -->
              <div class="slideshow-container">

                <!-- Full-width images with number and caption text -->
                <div class="mySlides3 fade">                
                  <img src="./static/images/carla_3.gif" style="width:60%">
                </div>
                <div class="mySlides3 fade">                
                  <img src="./static/images/carla_4.gif" style="width:60%">
                </div>
                <div class="mySlides3 fade">                
                  <img src="./static/images/carla_5.gif" style="width:60%">
                </div>
              </div>
              <!-- <br> -->

              <!-- The dots/circles -->
              <div style="text-align:center">
                <span class="dot3" onclick="currentSlide4(1)"></span>
                <span class="dot3" onclick="currentSlide4(2)"></span>
                <span class="dot3" onclick="currentSlide4(3)"></span>
              </div>
            </div>
          </div>
        </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-five-fifths">
            <h2 class="title is-4">ROAD Dataset</h2>
            <div class="content has-text-centered">
              <!-- <video id="replay-video"
                      controls
                      muted
                      preload
                      playsinline
                      width="75%">
                <source src="./static/gif/localization_anticipation.gif"
                        type="video/webm">
              </video> -->
              <!-- Slideshow container -->
              <div class="slideshow-container">

                <!-- Full-width images with number and caption text -->
                <div class="mySlides3 fade">                
                  <img src="./static/images/road_1.gif" style="width:60%">
                </div>
                <div class="mySlides3 fade">                
                  <img src="./static/images/road_2.gif" style="width:60%">
                </div>
                <div class="mySlides3 fade">                
                  <img src="./static/images/road_3.gif" style="width:60%">
                </div>
              </div>
              <!-- <br> -->

              <!-- The dots/circles -->
              <div style="text-align:center">
                <span class="dot3" onclick="currentSlide4(1)"></span>
                <span class="dot3" onclick="currentSlide4(2)"></span>
                <span class="dot3" onclick="currentSlide4(3)"></span>
              </div>
            </div>
          </div>
        </div>

<hr>

<section class="section is-max-desktop">
  <div class="container is-max-desktop">
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3">Environment Settings</h2>
    </div>
    <div class="flex-container">
      <img src="./static/images/blank.png" class="image-row-blank">
      <img src="./static/images/taco_road_dist" class="image-row-center">
      <img src="./static/images/blank.png" class="image-row-blank">
    </div>
    <div class="content has-text-justified">
      <p>
        Our environment setting.
      </p>
    </div>

    <div class="flex-container">
      <img src="./static/images/blank.png" class="image-row-blank">
      <img src="./static/images/simulation_object_hooks.png" class="image-row-center">
      <img src="./static/images/blank.png" class="image-row-blank">
    </div>
    <div class="flex-container">
      <img src="./static/images/blank.png" class="image-row-blank">
      <img src="./static/images/real_objects_hooks.png" class="image-row-center">
      <img src="./static/images/blank.png" class="image-row-blank">
    </div>
    <div class="content has-text-justified">
      <p>
        For simulation evaluation, we assess the performance of all methods by measuring their success rates and 
        inference times across <b>3,000 hanging processes involving 50 objects and 60 unseen supporting items</b> (Top). 
        These supporting items are manually categorized into four levels of difficulty: Easy, Normal, Hard, and Very
        Hard based on the complexity of the hanging part on them, with 15 assigned to each level.
        For real-world evaluation, we used a total of 10 objects and 10 supporting items for our hanging evaluation (Bottom).
      </p>
    </div>
  </div>
</section>


<section class="section is-max-desktop">
  <div class="container is-max-desktop">
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3">Benchmark on the TACO Dataset</h2>
    </div>
    <div class="content hs-text-jstified">
      <h3 style="text-align: center;">Table 1: </h3>
      <table>
        <tr>
          <th class="rowhead-border"></th>
          <th>Parameters (M)</th>
          <th>Sequence length</th>
          <th>mAP (vehicle)</th>
          <th>mAP (pedestrian)</th>
          <th>mAP</th>
        </tr>
        <tr class="middle-border">
          <td>I3D</td>
          <td>27.3</td>
          <td>8</td>
          <td>55.2</td>
          <td>51.8</td>
          <td>53.8</td>
        </tr>
        <tr>
          <td>X3D</td>
          <td>3.0</td>
          <td>16</td>
          <td>67.4</td>
          <td>59.0</td>
          <td>64.0</td>
        </tr>
        <tr>
          <td>CSN</td>
          <td>21.4</td>
          <td>32</td>
          <td>69.3</td>
          <td>61.9</td>
          <td>66.3</td>
        </tr>
        <tr>
          <td>SlowFast</td>
          <td>33.7</td>
          <td>32</td>
          <td>61.4</td>
          <td>58.1</td>
          <td>53.1</td>
        </tr>
        <tr class="middle-border">
          <td>MViT</td>
          <td>57.9</td>
          <td>16</td>
          <td>59.4</td>
          <td>45.0</td>
          <td>53.7</td>
        </tr>
        <tr>
          <td>VideoMAE</td>
          <td>57.9</td>
          <td>16</td>
          <td>69.9</td>
          <td>50.9</td>
          <td>62.3</td>
        </tr>
        <tr class="middle-border">
          <td>ARG</td>
          <td>12.2</td>
          <td>16</td>
          <td>54.6</td>
          <td><44.1</td>
          <td><50.4</td>
        </tr>
        <tr>
          <td>ARG*</td>
          <td>12.2</td>
          <td>16</td>
          <td>56.7</td>
          <td>48.3</td>
          <td>53.4</td>
        </tr>
        <tr>
          <td>ORN</td>
          <td>4.8</td>
          <td>16</td>
          <td>51.3</td>
          <td>43.1</td>
          <td>48.0</td>
        </tr>
        <tr>
          <td>ORN*</td>
          <td>4.8</td>
          <td>16</td>
          <td>53.3</td>
          <td>48.7</td>
          <td>51.5</td>
        </tr>
        <tr class="middle-border">
          <td>SAVi</td>
          <td>2.3</td>
          <td>16</td>
          <td>53.9</td>
          <td><47.1</td>
          <td><51.0</td>
        </tr>
        <tr>
          <td>MO</td>
          <td>2.3</td>
          <td>16</td>
          <td>50.7</td>
          <td>53.5</td>
          <td>51.8</td>
        </tr>
        <tr>
          <td>Slot-VPS</td>
          <td>2.3</td>
          <td>16</td>
          <td>67.0</td>
          <td>62.9</td>
          <td>65.4</td>
        </tr>
        <tr class="middle-border">
          <td>Action-Slot (I3D)</td>
          <td>2.3</td>
          <td>8</td>
          <td>58.3</td>
          <td>55.2</td>
          <td>56.5</td>
        </tr>
        <tr>
          <td>Action-Slot (X3D)</td>
          <td>2.3</td>
          <td>16</td>
          <td>74.7</td>
          <td>69.3</td>
          <td>72.6</td>
        </tr>
        <tr>
          <td>Action-slot (SlowFast)</td>
          <td>2.3</td>
          <td>32</td>
          <td>65.7</td>
          <td>63.5</td>
          <td>64.8</td>
        </tr>
      </table>
      <p>
      </p>

      </p>
    </div>
  </div> 
</section>


<section class="section is-max-desktop">
  <div class="container is-max-desktop">
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3">Benchmark on the ROAD Dataset</h2>
    </div>
    <div class="content hs-text-jstified">
      <h3 style="text-align: center;">Table 1: </h3>
      <table>
        <tr>
          <th class="rowhead-border"></th>
          <th>pretrained on TACO</th>
          <th>trained from scratch on ROAD</th>
          <th>pretrained on TACO + fine-tune on ROAD</th>
        </tr>
        <tr class="middle-border">
          <td>I3D</td>
          <td>19.5</td>
          <td>33.4</td>
          <td>40.5</td>
        </tr>
        <tr>
          <td>X3D</td>
          <td>20.0</td>
          <td>41.8</td>
          <td>43.3</td>
        </tr>
        <tr>
          <td>SlowFast</td>
          <td>27.2</td>
          <td>40.7</td>
          <td>56.4</td>
        </tr>
        <tr>
          <td>VideoMAE</td>
          <td>24.7</td>
          <td>26.8</td>
          <td>29.2</td>
        </tr>
        <tr class="middle-border">
        <tr>
          <td>MO</td>
          <td>33.8</td>
          <td>40.6</td>
          <td>46.0</td>
        </tr>
        <tr>
          <td>Slot-VPS</td>
          <td>30.8</td>
          <td>36.7</td>
          <td>52.1</td>
        </tr>
        <tr class="middle-border">
          <td>Action-Slot (I3D)</td>
          <td>24.6</td>
          <td>35.6</td>
          <td>46.3 (+5.8%)</td>
        </tr>
        <tr>
          <td>Action-slot (X3D)</td>
          <td>31.3</td>
          <td>40.1</td>
          <td>54.4 (+11.1%)</td>
        </tr>
        <tr>
          <td>Action-slot (SlowFast)</td>
          <td>36.8</td>
          <td>37.5</td>
          <td>62.5 (+6.1%)</td>
        </tr>
      </table>

      </p>
    </div>
  </div> 
</section>

<hr>

<section class="section is-max-desktop">
  <div class="container is-max-desktop">
    <div class="column is-centered has-text-centered">
      <h2 class="title is-3">Dataset Details</h2>
    </div>
<!--     <div class="content has-text-justified">
      <h3 style="text-align: center;">The Shape-Conditioned Trajectory Deformation Network (SCTDN)</h3>
    </div> -->
    <div class="content hs-text-jstified">
      <h3 style="text-align: center;">Table 1: </h3>
      <table>
        <tr>
          <th> </th>
          <th>size (minutes)</th>
          <th># of clips</th>
          <th># of labels</th>
        </tr>
        <tr class="middle-border">
          <td>ROAD</td>
          <td>134</td>
          <td>N/A</td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>annotated ROAD</td>
          <td>27</td>
          <td>127</td>
          <td>338</td>
        </tr>
        <tr class="middle-border">
          <td>TACO</td>
          <td>284</td>
          <td>3130</td>
          <td>7584</td>
        </tr>
      </table>
    </div>
      <p>
        Building on the well-established advancements in object keypoint prediction, our proposed representation and the 
        learning framework aims to tackle the challenge of effectively determining the appropriate actions for object hanging tasks.
      </p>
    </div>
    <div class="content has-text-justified">
      <img src="./static/images/statistics.png">
    </div>
  </div>
</section>


<hr>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{skthang2023,
  title={Action-Slot: Visual Action-centric Representation for Traffic Pattern Recognition},
  author={Chi-Hsi Kung, Shu-Wei Lu, Yi-Hsuan Tsai, Yi-Ting Chen},
  year={2023},
  booktitle={arXiv},
}
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/images/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template modified from <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">NeRFies</a>.
          <p>
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
